{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ada9f0-63a7-401c-add1-eab40292ada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1(Ans)Euclidean distance is the shortest path between source and destination which is a straight line.\n",
    "But Manhattan distance is sum of all the real distances between source(s) and destination(d) and each distance are always the straight lines.\n",
    "\n",
    "The experimental results show that the performance of KNN classifier depends significantly on the distance used, \n",
    "and the results showed large gaps between the performances of different distances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71d67f7-c723-48b8-a4f5-d65373173871",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2(Ans) The optimal K value usually found is the square root of N, where N is the total number of samples.\n",
    "Elbow Curve Method is used to determine the optimal k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad2c17-122e-47da-a103-d4b035b7c55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3(Ans)The experimental results show that the performance of KNN classifier depends significantly on the distance used, \n",
    "and the results showed large gaps between the performances of different distances.\n",
    "\n",
    "Both Euclidean and Manhattan distances are used in case of continuous variables, whereas hamming distance is used in case of categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ff10e3-4057-4b6f-89c0-e8e7521d094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4(Ans) Important parameters are -\n",
    "n_neighbors,algorithm\n",
    "Hyperparameters are parameters whose values control the learning process \n",
    "and determine the values of model parameters that a learning algorithm ends up learning. \n",
    "\n",
    "*After doing Hyperparameter we get the best_param_ value  which increase the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a82aae-d4e1-4199-b8e7-c2dfdee1e68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5(Ans)The KNN algorithm does not work well with large datasets. \n",
    "The cost of calculating the distance between the new point and each existing point is huge, which degrades performance.\n",
    "\n",
    "Gradient Descent. Gradient descent is an optimization technique commonly used in training machine learning algorithms. \n",
    "The main aim of training ML algorithms is to adjust the weights w to minimize the loss or cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707bf383-6a46-4804-aa78-b740929746fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6(Ans) KNN has some drawbacks and challenges, such as computational expense, slow speed, memory and storage issues for large datasets,\n",
    "sensitivity to the choice of k and the distance metric, and susceptibility to the curse of dimensionality.\n",
    "\n",
    "TO overcome from this  drawbacks to improve the performance of the model we use\n",
    "KD TREE and BALL TREE Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bea50b4-005b-4256-8e5b-cff8c006193e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3179a90c-a01d-4665-b9f4-9cecc0fb892d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
